{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91821c73-e14f-4f57-b030-4b08894fa1ca",
   "metadata": {},
   "source": [
    "# Neuroscience using `fastplotlib` :D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3551a7-089a-4254-90d0-8511b5ae3376",
   "metadata": {},
   "source": [
    "This notebook will build up a complex visualization using `fastplotlib`, in conjunction with other Python neuroscience packages, to exemplify how `fastplotlib` can be a powerful tool in analysis and visualization of neural data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de8062db-f3fa-4fd5-b788-a6aafdc9dbaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f4c4660-8430-4162-af75-4a1672e2d63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastplotlib as fpl\n",
    "import pynapple as nap\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from ipywidgets.widgets import VBox, HBox, IntSlider, Layout\n",
    "from mesmerize_core import *\n",
    "from sidecar import Sidecar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec01280b-0710-4d4d-a696-b837711e3826",
   "metadata": {},
   "source": [
    "### Opening behavior videos using **Lazy Loading** and visualizing them using `fastplotlib`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020a6330-6c16-4bcf-ba7e-02e6c1721abb",
   "metadata": {},
   "source": [
    "#### **Lazy Loading**: strategy to conserve RAM by dynamically loading in frames for visualization only as needed \n",
    "\n",
    "Behavioral and neural data collected during experiments can be up to **terabytes** in size making it impossible to load all of the data into RAM at once for visualization and analysis. ***Lazy Loading*** allows us to bypass this memory space constraint without overburdening our resources!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51446cb4-d0c3-4fbc-8e87-df602d9a7783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper class from mesmerize_core for lazy loading\n",
    "from mesmerize_core.arrays import LazyVideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf414f11-2fc9-43c3-9856-f5818b051b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Path('/data/kushal/cortex-learning/2p-trial-exps/eaf1/behavior/session4/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368aa738-f37d-4c6f-a102-ceb0c410295b",
   "metadata": {},
   "source": [
    "#### Get video paths for a single trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17d51e6f-a63c-4adf-85c1-41c2e24a9b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/data/kushal/cortex-learning/2p-trial-exps/eaf1/behavior/session4/eaf1-s4_front_v018.avi'),\n",
       " PosixPath('/data/kushal/cortex-learning/2p-trial-exps/eaf1/behavior/session4/eaf1-s4_side_v018.avi')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_one = sorted(list(data.glob(\"*018.avi\")))\n",
    "trial_one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc08ee5-dd30-47dd-b31c-cd72d0d24c72",
   "metadata": {},
   "source": [
    "#### Make an `ImageWidget` to view the trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "658cdfd4-1a40-410a-b270-968c618bf99f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ced10c9-d081-421e-bdd0-1129159f5ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e3a8161c4a40fc9f4a949bde343653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RFBOutputContext()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config found!\n",
      "No config found!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac4552949e54af592dbb5e9f49ffb3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "JupyterOutputContext(children=(JupyterWgpuCanvas(), IpywidgetToolBar(children=(Button(icon='expand-arrows-alt'â€¦"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iw = fpl.ImageWidget(\n",
    "    data=[LazyVideo(v) for v in trial_one], \n",
    "    names=[\"front\", \"side\"],\n",
    "    histogram_widget=False)\n",
    "\n",
    "iw.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136b49d7-13d7-4e03-8e93-5c506f5a827e",
   "metadata": {},
   "source": [
    "### Visualizing results of running `CaImAn` via `mesmerize-core` on calcium imaging data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4003cd9a-85c9-4dc1-ab4c-ffc6262e0e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/data/kushal/cortex-learning/2p-trial-exps')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_parent_raw_data_path('/data/kushal/cortex-learning/2p-trial-exps/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a6863d5-41cc-44ed-b05a-0b622b616b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo</th>\n",
       "      <th>item_name</th>\n",
       "      <th>input_movie_path</th>\n",
       "      <th>params</th>\n",
       "      <th>outputs</th>\n",
       "      <th>comments</th>\n",
       "      <th>uuid</th>\n",
       "      <th>added_time</th>\n",
       "      <th>ran_time</th>\n",
       "      <th>algo_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cnmf</td>\n",
       "      <td>eaf1_session4</td>\n",
       "      <td>eaf1/calcium/session4/eaf4-s4-filtered-bilater...</td>\n",
       "      <td>{'main': {'fr': 15, 'p': 1, 'nb': 2, 'merge_th...</td>\n",
       "      <td>{'success': False, 'traceback': 'Traceback (mo...</td>\n",
       "      <td>None</td>\n",
       "      <td>cc11149a-07d6-44ae-ba1a-f572744878c6</td>\n",
       "      <td>2023-01-23T18:10:34</td>\n",
       "      <td>2023-01-23T18:11:01</td>\n",
       "      <td>9.32 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cnmf</td>\n",
       "      <td>eaf1_session4</td>\n",
       "      <td>eaf1/calcium/session4/filtered-concat_session4...</td>\n",
       "      <td>{'main': {'fr': 15, 'p': 1, 'nb': 2, 'merge_th...</td>\n",
       "      <td>{'mean-projection-path': e1421f9b-d01a-4823-82...</td>\n",
       "      <td>None</td>\n",
       "      <td>e1421f9b-d01a-4823-8237-81a5ad7a952f</td>\n",
       "      <td>2023-01-23T19:08:59</td>\n",
       "      <td>2023-01-23T19:19:32</td>\n",
       "      <td>618.75 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cnmf</td>\n",
       "      <td>eaf1_session4</td>\n",
       "      <td>eaf1/calcium/session4/filtered-concat_session4...</td>\n",
       "      <td>{'main': {'fr': 15, 'p': 1, 'nb': 2, 'merge_th...</td>\n",
       "      <td>{'mean-projection-path': 102e7ec8-bcdd-49ad-9a...</td>\n",
       "      <td>None</td>\n",
       "      <td>102e7ec8-bcdd-49ad-9a96-b4ef4041e70f</td>\n",
       "      <td>2023-01-23T20:17:17</td>\n",
       "      <td>2023-01-23T20:28:23</td>\n",
       "      <td>658.97 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cnmf</td>\n",
       "      <td>eaf1_session4</td>\n",
       "      <td>eaf1/calcium/session4/filtered-concat_session4...</td>\n",
       "      <td>{'main': {'fr': 15, 'p': 1, 'nb': 2, 'merge_th...</td>\n",
       "      <td>{'mean-projection-path': 15118c77-e199-4baf-a3...</td>\n",
       "      <td>None</td>\n",
       "      <td>15118c77-e199-4baf-a35f-eb6b2c9c4a69</td>\n",
       "      <td>2023-01-23T20:36:59</td>\n",
       "      <td>2023-01-23T20:46:54</td>\n",
       "      <td>561.09 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>cnmf</td>\n",
       "      <td>eaf1_session4</td>\n",
       "      <td>eaf1/calcium/session4/filtered-concat_session4...</td>\n",
       "      <td>{'main': {'fr': 15, 'p': 1, 'nb': 2, 'merge_th...</td>\n",
       "      <td>{'mean-projection-path': 9b0f79f7-cbad-40d2-a1...</td>\n",
       "      <td>None</td>\n",
       "      <td>9b0f79f7-cbad-40d2-a1ef-f24fe6038cbb</td>\n",
       "      <td>2023-01-23T20:37:04</td>\n",
       "      <td>2023-01-23T21:02:48</td>\n",
       "      <td>542.55 sec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    algo      item_name                                   input_movie_path  \\\n",
       "22  cnmf  eaf1_session4  eaf1/calcium/session4/eaf4-s4-filtered-bilater...   \n",
       "23  cnmf  eaf1_session4  eaf1/calcium/session4/filtered-concat_session4...   \n",
       "24  cnmf  eaf1_session4  eaf1/calcium/session4/filtered-concat_session4...   \n",
       "25  cnmf  eaf1_session4  eaf1/calcium/session4/filtered-concat_session4...   \n",
       "26  cnmf  eaf1_session4  eaf1/calcium/session4/filtered-concat_session4...   \n",
       "\n",
       "                                               params  \\\n",
       "22  {'main': {'fr': 15, 'p': 1, 'nb': 2, 'merge_th...   \n",
       "23  {'main': {'fr': 15, 'p': 1, 'nb': 2, 'merge_th...   \n",
       "24  {'main': {'fr': 15, 'p': 1, 'nb': 2, 'merge_th...   \n",
       "25  {'main': {'fr': 15, 'p': 1, 'nb': 2, 'merge_th...   \n",
       "26  {'main': {'fr': 15, 'p': 1, 'nb': 2, 'merge_th...   \n",
       "\n",
       "                                              outputs comments  \\\n",
       "22  {'success': False, 'traceback': 'Traceback (mo...     None   \n",
       "23  {'mean-projection-path': e1421f9b-d01a-4823-82...     None   \n",
       "24  {'mean-projection-path': 102e7ec8-bcdd-49ad-9a...     None   \n",
       "25  {'mean-projection-path': 15118c77-e199-4baf-a3...     None   \n",
       "26  {'mean-projection-path': 9b0f79f7-cbad-40d2-a1...     None   \n",
       "\n",
       "                                    uuid           added_time  \\\n",
       "22  cc11149a-07d6-44ae-ba1a-f572744878c6  2023-01-23T18:10:34   \n",
       "23  e1421f9b-d01a-4823-8237-81a5ad7a952f  2023-01-23T19:08:59   \n",
       "24  102e7ec8-bcdd-49ad-9a96-b4ef4041e70f  2023-01-23T20:17:17   \n",
       "25  15118c77-e199-4baf-a35f-eb6b2c9c4a69  2023-01-23T20:36:59   \n",
       "26  9b0f79f7-cbad-40d2-a1ef-f24fe6038cbb  2023-01-23T20:37:04   \n",
       "\n",
       "               ran_time algo_duration  \n",
       "22  2023-01-23T18:11:01      9.32 sec  \n",
       "23  2023-01-23T19:19:32    618.75 sec  \n",
       "24  2023-01-23T20:28:23    658.97 sec  \n",
       "25  2023-01-23T20:46:54    561.09 sec  \n",
       "26  2023-01-23T21:02:48    542.55 sec  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load mesmerize batch that has already been run for this animal\n",
    "df = load_batch(get_parent_raw_data_path().joinpath('eaf1/calcium/batch/batch.pickle'))\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9af748-063b-4e8b-b746-8bf688a6f5d0",
   "metadata": {},
   "source": [
    "#### We are going to use the results of row 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22cacb7c-300e-4c3f-bb76-49cf568ee9b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "row_ix = 26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e137871a-edcc-4b85-a055-37760f8a0ed9",
   "metadata": {},
   "source": [
    "#### Get the motion corrected movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5469fce7-dc6d-45d7-8ad4-660af2315f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = df.iloc[row_ix].caiman.get_input_movie()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058d21cf-6f24-4f47-ae95-55ad674e6d7a",
   "metadata": {},
   "source": [
    "#### Get contours and SNR components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "760aa1f1-fcb6-460c-9c34-e9ee5a19d1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.24249106,  0.10373908, -0.13939034, -0.15015753,  0.08204876,\n",
       "       -0.1908793 , -0.05140921, -0.17028186,  0.16581392,  0.44946934])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the contours and center of masses using mesmerize_core\n",
    "contours, coms = df.iloc[row_ix].cnmf.get_contours(component_indices=\"good\", swap_dim=False)\n",
    "\n",
    "# get the signal-to-noise ratio of each \"good\" component to color components \n",
    "snr_comps = df.iloc[row_ix].cnmf.get_output().estimates.SNR_comp\n",
    "\n",
    "# get the good component_ixs\n",
    "good_ixs = df.iloc[row_ix].cnmf.get_good_components()\n",
    "\n",
    "# only get snr_comps of good_ixs\n",
    "snr_comps = snr_comps[good_ixs]\n",
    "\n",
    "np.log10(snr_comps)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc44e783-c5bc-4a25-9921-2c5cfe782587",
   "metadata": {},
   "source": [
    "### Components with low SNR will **purple** and those with higher SNR ratio will be **yellow**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2c44f6-cf75-4a43-ab38-d8d38894cd3e",
   "metadata": {},
   "source": [
    "### Creating an interactive viualization to help with analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58e0180-02be-450f-9f82-db5336b3f4b6",
   "metadata": {},
   "source": [
    "Will need a euclidean helper function to indentify which contours has been clicked on. We hope to soon include this, and other common callback functions, in our interactivity system :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "665ea49c-4a5d-4417-8095-320b35f203a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean(source, target, event, new_data):\n",
    "    \"\"\"maps click events to contour\"\"\"\n",
    "    # calculate coms of line collection\n",
    "    indices = np.array(event.pick_info[\"index\"])\n",
    "    \n",
    "    coms = list()\n",
    "\n",
    "    for contour in target.graphics:\n",
    "        coors = contour.data()[~np.isnan(contour.data()).any(axis=1)]\n",
    "        com = coors.mean(axis=0)\n",
    "        coms.append(com)\n",
    "\n",
    "    # euclidean distance to find closest index of com \n",
    "    indices = np.append(indices, [0])\n",
    "    \n",
    "    ix = int(np.linalg.norm((coms - indices), axis=1).argsort()[0])\n",
    "    \n",
    "    target.set_feature(feature=\"colors\", new_data=new_data, indices=ix)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0e7493-e149-4656-966d-55ba2a38d929",
   "metadata": {},
   "source": [
    "#### Create a layout to display the raw neural activity and associated temporal data for each identified neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "663cbf0b-5e64-4188-a9c9-1ffa9dded2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ad29ce92ee4c1da576aaff52058d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RFBOutputContext()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7f9047e171e40b8b8896bd5666c9e29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RFBOutputContext()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create image widget for raw neural activity \n",
    "raw_iw = fpl.ImageWidget(\n",
    "    data=[raw],\n",
    "    names=[\"raw\"]\n",
    ")\n",
    "\n",
    "# re-add our identified good components from before using the SNR mapping\n",
    "contours_graphic = raw_iw.gridplot[\"raw\"].add_line_collection(\n",
    "                                                    data=contours, \n",
    "                                                    # use our snr components as cmap values\n",
    "                                                    cmap_values=np.log10(snr_comps),\n",
    "                                                    cmap=\"spring\",\n",
    "                                                    thickness=2,\n",
    "                                                    name=\"contours\")\n",
    "\n",
    "# get temporal components\n",
    "temporal = df.iloc[row_ix].cnmf.get_temporal(component_indices=\"good\")\n",
    "\n",
    "# temporal plot\n",
    "plot_temporal = fpl.Plot(size=(600,100))\n",
    "plot_temporal.add_line(temporal[0], colors=\"magenta\")\n",
    "\n",
    "# add a linear selector to temporal trace\n",
    "plot_temporal.graphics[0].add_linear_selector()\n",
    "\n",
    "# show temporal plot and mcorr/rcm plot in ipywidgets VBox \n",
    "sc = Sidecar()\n",
    "\n",
    "with sc:\n",
    "    display(VBox([raw_iw.show(), plot_temporal.show()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "543c0a90-d89d-4aeb-bfff-f91a982c594d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# link the linear selector to the image widget time slider\n",
    "plot_temporal.selectors[0].add_ipywidget_handler(raw_iw.sliders[\"t\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43493a01-4b83-4897-8e6f-82590297f4eb",
   "metadata": {},
   "source": [
    "#### Interacitvity of `Graphics` using `link()` and callback functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "420813af-8468-4497-bbaa-a277e03938e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# link image to contours\n",
    "image_graphic = raw_iw.gridplot[\"raw\"][\"image_widget_managed\"]\n",
    "\n",
    "image_graphic.link(\n",
    "    \"click\",\n",
    "    target=contours_graphic,\n",
    "    feature=\"colors\", \n",
    "    new_data=\"white\", \n",
    "    callback=euclidean\n",
    ")\n",
    "\n",
    "# callback function to display correct temporal trace\n",
    "def update_temporal(ev):\n",
    "    # get data of selected ix\n",
    "    data = temporal[ev.pick_info[\"collection-index\"]]\n",
    "    \n",
    "    # add trace to plot \n",
    "    plot_temporal.graphics[0].data = data\n",
    "    \n",
    "    # autoscale the temporal plot\n",
    "    plot_temporal.auto_scale()\n",
    "\n",
    "# add event handler so that temporal trace is generated when contour is clicked on\n",
    "contours_graphic[:].colors.add_event_handler(update_temporal)\n",
    "\n",
    "# thickness of contour\n",
    "contours_graphic.link(\"colors\", target=contours_graphic, feature=\"thickness\", new_data=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c87dad08-dc63-426c-83f0-4bc4a8fc622f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_temporal.close()\n",
    "raw_iw.close()\n",
    "sc.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358e0beb-ecf0-4f2d-bae1-2b789ebb6604",
   "metadata": {},
   "source": [
    "### Syncing behavior and calcium data using `pynapple`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b6ad30-188d-4fc0-8f1e-79a06e168a4c",
   "metadata": {},
   "source": [
    "Having data input streams collected at different frame rates is a common problem. Here we will use `pynapple` in order to sync our two datastreams for future analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dead909-b503-42f1-b3ba-a9cecaa09220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6aa5eef-3784-4c92-8a1f-7752ebe785cb",
   "metadata": {},
   "source": [
    "#### We have pre-concatenated all of the behavior videos for this session to reduce the amount of boilerplate code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59d28c3f-2366-4973-9e05-81c6b8b0ec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_behavior = tifffile.memmap(\"/home/clewis7/Desktop/sfn_data/preconcat.tiff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea3d3dd3-5064-4c13-8c6c-d20fcd359d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318850, 256, 336)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_behavior.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c837ed-2cff-4d43-a422-e618de4b9ed4",
   "metadata": {},
   "source": [
    "#### Recording Frame Rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a1f220b-49ab-4440-a2e4-bcbf87f7cdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_fr = 500\n",
    "calcium_fr = 15.2414"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb571025-82b3-4c2e-a045-b0bcb912ab2f",
   "metadata": {},
   "source": [
    "#### Create `pynapple` tensors for behavior and calcium data based on frame rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8eb3370-0cc1-4855-898b-a06be4c289b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a timestamp for the behavioral video\n",
    "t_behavior = np.linspace(0, concat_behavior.shape[0] / behavior_fr, concat_behavior.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad16f013-3a6e-4901-ab75-4ea0e72ce38b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318850,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_behavior.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "662d958f-ed86-4719-a93c-dc5f11d698fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "637.7"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_behavior[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a612e9-92bb-4a84-b154-fafcfa46abd7",
   "metadata": {},
   "source": [
    "#### Use `pynapple` to create an indexable tensor of our behavioral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1526620a-46a5-484a-b7f0-e40d22eb0c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsd_video = nap.TsdTensor(t_behavior, concat_behavior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34cdbfbd-6b58-4a7a-8268-8c1d7e8d5868",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time (s)\n",
       "-------------  -----------------\n",
       "0.0            [[0 ... 9] ...]\n",
       "0.002000006    [[0 ... 9] ...]\n",
       "0.004000013    [[0 ... 9] ...]\n",
       "0.006000019    [[15 ... 9] ...]\n",
       "0.008000025    [[10 ... 9] ...]\n",
       "...\n",
       "637.691999975  [[29 ... 10] ...]\n",
       "637.693999981  [[25 ... 10] ...]\n",
       "637.695999987  [[20 ... 10] ...]\n",
       "637.697999994  [[25 ... 10] ...]\n",
       "637.7          [[25 ... 10] ...]\n",
       "dtype: uint8, shape: (318850, 256, 336)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all of our time points and corresponding behavior frames mapped\n",
    "tsd_video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2f1528-783d-4786-9c97-ebb77af0f966",
   "metadata": {},
   "source": [
    "#### Do the same for our calcium data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f326651-1bd5-46e1-b084-8135d1384304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a timestamp for the calcium video\n",
    "t_calcium = np.linspace(0, raw.shape[0] / calcium_fr, raw.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56112216-ffcc-438d-b7bf-deff06df9c8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9153,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_calcium.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dca71276-617e-406a-9cda-5ab6f64525f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600.5353838886191"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_calcium[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faa2ff8-f224-4bc5-9626-48c630ce4374",
   "metadata": {},
   "source": [
    "#### Use `pynapple` to create an indexable tensor of our calcium data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4247883f-bd19-49a0-8e4c-ce84b9d3eac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsd_calcium = nap.TsdTensor(t_calcium, raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2129304d-87df-4262-9576-d8f32bc9ae4e",
   "metadata": {},
   "source": [
    "#### Create a `GridPlot` for calcium and concatenated behavior videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328c1244-1274-400b-a269-bcab3eca4e91",
   "metadata": {},
   "source": [
    "Here we are going to create a `GridPlot` and manually update the data in each subplot as we slide through time using our previously created `pynapple` tensors. \n",
    "\n",
    "The reason that we cannot use an `ImageWidget` here is because the framerate of our behavioral and calcium data is different. `ImageWidget` assumes that the data arrays in each subplot are all of the same framerate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "688330d7-7a02-4f90-8387-7c4acaa34665",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e32322c8bd474ea5bb52695e26a081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RFBOutputContext()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<weakproxy at 0x7f8fd83278d0 to ImageGraphic at 0x7f8fd8018050>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nap_plot = fpl.GridPlot(shape=(1,2), names=[[\"raw\", \"behavior\"]])\n",
    "\n",
    "nap_plot[\"raw\"].add_image(data=raw[0], name=\"raw_frame\")\n",
    "nap_plot[\"behavior\"].add_image(data=tsd_video[0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fb9679-3855-4a57-93a0-00e219dcb954",
   "metadata": {},
   "source": [
    "#### Create slider that updates behavior and calcium data so they are aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a15afa9a-fddf-4e26-9af8-0413f4284f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This time will be in milliseconds\n",
    "synced_time = IntSlider(min=0, max=22*19 * 1_000, description=\"ms\", layout=Layout(width=\"500\"))\n",
    "\n",
    "def update_time(change):\n",
    "    # get the index of synced slider\n",
    "    time_ms = change[\"new\"]\n",
    "    # get the corresponding calcium frame from the pynapple tensor\n",
    "    frame_raw = tsd_calcium.get(time_ms, time_units=\"ms\")\n",
    "    # update the data in the plot\n",
    "    nap_plot[\"raw\"].graphics[0].data = frame_raw\n",
    "    # get the corresponding behavior frame from the pynapple tensor\n",
    "    frame_behavior = tsd_video.get(time_ms, time_units=\"ms\")\n",
    "    # update the data in the plot\n",
    "    nap_plot[\"behavior\"].graphics[0].data = frame_behavior\n",
    "\n",
    "synced_time.observe(update_time, \"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da76fee-36a5-4711-b7f9-6a3798efd2a3",
   "metadata": {},
   "source": [
    "#### Re-create temporal plot and link to click events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4858d09b-1dae-4501-8d2e-b33e8083063a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# linear interpolation wrapper for temporal traces to expand the calcium timepoints to behavior\n",
    "def interpolate(data: np.ndarray, new_size: int):\n",
    "    \"\"\"\n",
    "    1D interpolation\n",
    "    \n",
    "    data is a 1d numpy array\n",
    "    new size is the size to interpolate to\n",
    "    \"\"\"\n",
    "    x = np.arange(0, new_size)\n",
    "    xp = np.linspace(0, new_size, data.size)\n",
    "    \n",
    "    # interpolate to new size\n",
    "    return np.interp(x, xp, fp=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f1df9cde-3d0d-47f8-81f9-f530fd24177a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37794600f3044bfd817fb66fe937fa97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RFBOutputContext()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# temporal plot\n",
    "plot_temporal = fpl.Plot(size=(600,100))\n",
    "\n",
    "interpolated_temporal = interpolate(data=temporal[0], new_size=t_behavior.shape[0])\n",
    "plot_temporal.add_line(interpolated_temporal, colors=\"magenta\")\n",
    "\n",
    "# add a linear selector to temporal trace\n",
    "plot_temporal.graphics[0].add_linear_selector()\n",
    "\n",
    "# re-add our identified good components from before using the SNR mapping\n",
    "contours_graphic = nap_plot[\"raw\"].add_line_collection(\n",
    "                                                    data=contours, \n",
    "                                                    # use our snr components as cmap values\n",
    "                                                    cmap_values=np.log10(snr_comps),\n",
    "                                                    cmap=\"spring\",\n",
    "                                                    thickness=2,\n",
    "                                                    name=\"contours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a9a80b64-619f-4321-9046-c51b3cf33be0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.change_sync_slider_size(ev)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# link image to contours\n",
    "image_graphic = nap_plot[\"raw\"][\"raw_frame\"]\n",
    "\n",
    "image_graphic.link(\n",
    "    \"click\",\n",
    "    target=contours_graphic,\n",
    "    feature=\"colors\", \n",
    "    new_data=\"white\", \n",
    "    callback=euclidean\n",
    ")\n",
    "\n",
    "# callback function to display correct temporal trace\n",
    "def update_temporal(ev):\n",
    "    # get data of selected ix\n",
    "    data = temporal[ev.pick_info[\"collection-index\"]]\n",
    "    \n",
    "    # add trace to plot \n",
    "    interpolated_temporal = interpolate(data=data, new_size=t_behavior.shape[0])\n",
    "    plot_temporal.graphics[0].data = interpolated_temporal\n",
    "    \n",
    "    # autoscale the temporal plot\n",
    "    plot_temporal.auto_scale()\n",
    "\n",
    "# add event handler so that temporal trace is generated when contour is clicked on\n",
    "contours_graphic[:].colors.add_event_handler(update_temporal)\n",
    "\n",
    "# thickness of contour\n",
    "contours_graphic.link(\"colors\", target=contours_graphic, feature=\"thickness\", new_data=5)\n",
    "\n",
    "def change_sync_slider_size(ev):\n",
    "    synced_time.layout = Layout(width=str(ev.width))\n",
    "\n",
    "# resize sliders based on temporal plot size\n",
    "plot_temporal.renderer.add_event_handler(change_sync_slider_size, \"resize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "040c3d22-797f-4144-8e19-cbbb53f53e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86495ea597504362b1f84c10fa879542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(JupyterOutputContext(children=(JupyterWgpuCanvas(), IpywidgetToolBar(children=(Button(icon='expâ€¦"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VBox([nap_plot.show(), plot_temporal.show(), synced_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "28382190-3b00-44b7-99d7-d74ab3b4990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# link the linear selector to the image widget time slider\n",
    "plot_temporal.selectors[0].add_ipywidget_handler(synced_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdd9e7a-468a-4a55-8d9c-ad6595e52c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
